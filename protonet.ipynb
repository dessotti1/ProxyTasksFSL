{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d9f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ 1. Importa√ß√µes\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seu modelo e utilit√°rios\n",
    "from model import DeiTForFewShot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3a0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßº 2. Transforma√ß√µes de pr√©-processamento\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554adc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detectadas no suporte: ['A', 'Airfield', 'Airplane', 'Avi√£o', 'Banheiro', 'Bus', 'C', 'Cafeteria', 'Camarim', 'Carro', 'Casa', 'Castelo', 'Castle', 'Estrada', 'Highway', 'Piscina', 'Quarto', 'Quarto de Crian√ßa', 'Sala de aula', 'Sala de estar', '√înibus']\n"
     ]
    }
   ],
   "source": [
    "# Diret√≥rios\n",
    "suporte_dir = \"dataset_suporte\"\n",
    "consulta_dir = \"dataset_consulta\"\n",
    "\n",
    "# Transforma√ß√µes (compat√≠vel com DeiT)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ou o que o seu backbone espera\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Listar subpastas (classes)\n",
    "classes = sorted(os.listdir(suporte_dir))\n",
    "print(\"Classes detectadas no suporte:\", classes)\n",
    "\n",
    "support_images = []\n",
    "support_labels = []\n",
    "\n",
    "# Atribuir um √≠ndice para cada classe\n",
    "classe_para_indice = {classe: idx for idx, classe in enumerate(classes)}\n",
    "\n",
    "# Percorrer cada classe e carregar imagens\n",
    "for classe in classes:\n",
    "    classe_path = os.path.join(suporte_dir, classe)\n",
    "    for nome_img in sorted(os.listdir(classe_path)):\n",
    "        img_path = os.path.join(classe_path, nome_img)\n",
    "        imagem = Image.open(img_path).convert(\"RGB\")\n",
    "        support_images.append(transform(imagem))\n",
    "        support_labels.append(classe_para_indice[classe])\n",
    "\n",
    "# Converter para tensores\n",
    "support_images = torch.stack(support_images)  # [N_supp, 3, 224, 224]\n",
    "support_labels = torch.tensor(support_labels) # [N_supp]\n",
    "\n",
    "# Agrupar por batch de 1\n",
    "support_images = support_images.unsqueeze(0)  # [1, N_supp, 3, 224, 224]\n",
    "support_labels = support_labels               # [N_supp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49f3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento da consulta\n",
    "query_images = torch.stack([\n",
    "    transform(Image.open(os.path.join(consulta_dir, img)).convert(\"RGB\"))\n",
    "    for img in sorted(os.listdir(consulta_dir))\n",
    "])\n",
    "query_images = query_images.unsqueeze(0)  # [1, N_query, 3, 224, 224]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "471e28ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser('Few-shot learning script', add_help=False)\n",
    "    # (copie aqui o conte√∫do do get_args_parser, s√≥ os add_argument)\n",
    "    \n",
    "    # --- Copie todos os add_argument daqui (ou importe diretamente do seu m√≥dulo) ---\n",
    "    parser.add_argument('--batch-size', default=1, type=int)\n",
    "    parser.add_argument('--epochs', default=100, type=int)\n",
    "    parser.add_argument('--output_dir', default='outputs/tmp',\n",
    "                      help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--deterministic', default=False, type=bool)\n",
    "    parser.add_argument('--experiment_name', default=\"\", help='name of the experiment running to create apropriate file.')\n",
    "    \n",
    "    parser.add_argument(\"--extract_features\", action='store_true')\n",
    "    parser.add_argument(\"--dataset_path\", default=\"\", type=str)\n",
    "\n",
    "    parser.add_argument(\"--classify\", action=\"store_true\")\n",
    "    parser.add_argument(\"--support_file\", type=str)\n",
    "    parser.add_argument(\"--query_file\", type=str)\n",
    "\n",
    "    parser.add_argument(\"--wandb\", dest='wandb', action='store_true')\n",
    "    parser.add_argument(\"--no-wandb\", dest='wandb', action='store_false')\n",
    "    parser.set_defaults(wandb=True)\n",
    "    parser.add_argument(\"--project-name\", default=\"FSL-Transformers\", type=str)\n",
    "\n",
    "    parser.add_argument(\"--dataset\", choices=[\"places\", \"places_600\", \"test\", \"final_test\", \"csam\", \"litmus\"],\n",
    "                      default=\"places_600\",\n",
    "                      help=\"Which few-shot dataset.\")\n",
    "\n",
    "    parser.add_argument(\"--nClsEpisode\", default=8, type=int,\n",
    "                      help=\"Number of categories in each episode.\")\n",
    "    parser.add_argument(\"--nSupport\", default=5, type=int,\n",
    "                      help=\"Number of samples per category in the support set.\")\n",
    "    parser.add_argument(\"--nQuery\", default=15, type=int,\n",
    "                      help=\"Number of samples per category in the query set.\")\n",
    "    parser.add_argument(\"--nEpisode\", default=2000, type=int,\n",
    "                      help=\"Number of episodes for training / testing.\")\n",
    "\n",
    "    parser.add_argument('--pretrained_weights', default='', type=str, help=\"Path to pretrained weights to evaluate.\")\n",
    "    parser.add_argument('--backbone', default='deit_small',choices=['deit', 'resnet50', 'dino', 'resnet50_dino', 'deit_small', 'resnet18', 'vit_mini'])\n",
    "    parser.add_argument('--aggregator', default='average', choices=['average', 'max', 'log_sum_exp', 'lp_pool', 'self_attn'])\n",
    "    parser.add_argument('--temperature', default=0.1, type=float, help='temperature to be applyed to cosine similarities')\n",
    "\n",
    "    parser.add_argument('--aug_prob', default=0.9, type=float, help='Probability of applying data augmentation during meta-testing')\n",
    "    parser.add_argument('--aug_types', nargs=\"+\", default=['color', 'translation'],\n",
    "                      help='color, offset, offset_h, offset_v, translation, cutout')\n",
    "\n",
    "    parser.add_argument('--img-size', default=224, type=int, help='images input size')\n",
    "\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                      help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--optimizer', type=str, default='sgd', choices=['sgd', 'adam'])\n",
    "\n",
    "    parser.add_argument('--sched', default='step', type=str, choices=[\"cosine\", \"step\", \"exponential\", \"None\"], metavar='SCHEDULER',\n",
    "                      help='LR scheduler (default: \"step\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-5, metavar='LR',\n",
    "                      help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                      help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                      help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                      help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                      help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-6, metavar='LR',\n",
    "                      help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=10, metavar='N',\n",
    "                      help='epoch interval to decay LR (step scheduler)')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=5, metavar='N',\n",
    "                      help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                      help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                      help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.5, metavar='RATE',\n",
    "                      help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                      help='Color jitter factor (default: 0.4)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                      help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                            \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.0, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                      help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                      help='start epoch')\n",
    "    parser.add_argument('--max_acc', default=None, type=tuple, help='Max accuracy obtained in training before')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                      help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                      help='cuda:gpu_id for single GPU training')\n",
    "\n",
    "    # --- Fim dos argumentos ---\n",
    "\n",
    "    args = parser.parse_args([])  # simula execu√ß√£o sem args da linha de comando\n",
    "\n",
    "    return args\n",
    "\n",
    "args = get_args()\n",
    "print(\"Args configurado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c3979d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DeiTModel were not initialized from the model checkpoint at facebook/deit-small-distilled-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import DeiTForFewShot  # ajuste o import conforme seu projeto\n",
    "\n",
    "# Carregando o modelo\n",
    "model = DeiTForFewShot(args)\n",
    "\n",
    "# Substitua pelo caminho correto do seu arquivo .pth\n",
    "checkpoint_path = \"proxyfsl/thamiris_FSL_places600_best.pth\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# checkpoint √© um dicion√°rio com v√°rias chaves, a parte do modelo fica em 'model'\n",
    "state_dict = checkpoint.get('model', checkpoint)  # tenta pegar o 'model', sen√£o usa todo\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(\"Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a7e8eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(\"proxyfsl/highway.jpg\").convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0) \n",
    "\n",
    "with torch.no_grad():\n",
    "    embedding = model.get_features(image)\n",
    "\n",
    "len(embedding[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
